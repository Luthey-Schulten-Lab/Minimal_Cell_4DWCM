{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: I DO NOT RECOMMEND RUNNING ALL FOR THIS NOTEBOOK\n",
    "# RUN ONE SET OF SIMULATION MERGES AT A TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "# import multiprocessing as mp\n",
    "# from functools import partial\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION FROM TIANYU\n",
    "# ADDED FOLLOWING OPTIONS TO create_dataset: compression=\"gzip\",compression_opts=1, chunks=(16,16,16,16)\n",
    "# OPTIONS WERE ADDED TO DRAMATICALLY REDUCE FILE SIZES\n",
    "\n",
    "def append_lm_files(file1_path, file2_path, chunk_size=10):\n",
    "    \"\"\"\n",
    "    Append trajectories from file2 directly to file1, renumbering frames to maintain sequential ordering.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file1_path : str\n",
    "        Path to the first LM file (will be modified in-place)\n",
    "    file2_path : str\n",
    "        Path to the second LM file\n",
    "    chunk_size : int, optional\n",
    "        Number of frames to process in each batch\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Path to the modified file1\n",
    "    \"\"\"\n",
    "    print(f\"Appending files:\\n  - {file2_path} â†’ {file1_path} (in-place)\")\n",
    "\n",
    "    # os.system(\"cp {file1_path} \")\n",
    "    \n",
    "    # Get frame information from both files\n",
    "    with h5py.File(file1_path, 'r') as file1, h5py.File(file2_path, 'r') as file2:\n",
    "        trajs1 = file1['Simulations']['0000001']['Lattice']\n",
    "        trajs2 = file2['Simulations']['0000001']['Lattice']\n",
    "        \n",
    "        # Get frame keys and determine the next frame number\n",
    "        frame_keys1 = sorted(list(trajs1.keys()))\n",
    "        frame_keys2 = sorted(list(trajs2.keys()))\n",
    "        \n",
    "        # Determine the highest frame number in file1\n",
    "        # Assuming frame keys are in format '0000000000' as a string\n",
    "        last_frame_num = int(frame_keys1[-1])\n",
    "        print(f\"File 1 has {len(frame_keys1)} frames, last frame is {last_frame_num}\")\n",
    "        print(f\"File 2 has {len(frame_keys2)} frames to append\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Open file1 for writing and file2 for reading\n",
    "    with h5py.File(file1_path, 'r+') as file1, h5py.File(file2_path, 'r') as file2:\n",
    "        trajs1 = file1['Simulations']['0000001']['Lattice']\n",
    "        trajs2 = file2['Simulations']['0000001']['Lattice']\n",
    "        \n",
    "        # Process each frame from file2 and append to file1\n",
    "        next_frame_num = last_frame_num + 1\n",
    "        \n",
    "        for i, frame_key in enumerate(tqdm(frame_keys2, desc=\"Appending frames\")):\n",
    "            # Get lattice data from file2\n",
    "            lattice2 = np.array(trajs2[frame_key])\n",
    "            \n",
    "            # Create new frame key with sequential numbering\n",
    "            new_frame_key = f\"{next_frame_num + i:010d}\"\n",
    "            \n",
    "            # Create the new dataset in file1\n",
    "            trajs1.create_dataset(new_frame_key, data=lattice2, compression=\"gzip\",compression_opts=1, chunks=(16,16,16,16))\n",
    "    \n",
    "    print(f\"Added {len(frame_keys2)} frames to {file1_path}\")\n",
    "    print(f\"New frame count: {next_frame_num + len(frame_keys2) - 1}\")\n",
    "    print(f\"Appending complete!\")\n",
    "    return file1_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "  \n",
    "#     file1 = \"/Data1/zane/Models/mincell/Mar10/Mar10_2/MinCell_merged.lm\"\n",
    "#     file2 = \"/Data1/zane/Models/mincell/Mar10/Mar10_2/MinCell_restart_5271.lm\"\n",
    "#     # Output will be saved in the file1\n",
    "#     # Use the modified append function to append directly to file1\n",
    "#     output = append_lm_files(\n",
    "#         file1, \n",
    "#         file2, \n",
    "#         chunk_size=10  # Process 10 frames at a time\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeReplicate(datDir, dateDir, repID, restart_times):\n",
    "\n",
    "    original = f'{datDir}{dateDir}{repID}/MinCell.lm'\n",
    "    merged = f'{datDir}{dateDir}{repID}/MinCell_merged.lm'\n",
    "\n",
    "    os.system(f'rm {merged}')\n",
    "\n",
    "    os.system(f'cp {original} {merged}')\n",
    "\n",
    "    for time in restart_times:\n",
    "\n",
    "        restart = f'{datDir}{dateDir}{repID}/MinCell_restart_{int(time)}.lm'\n",
    "\n",
    "        output = append_lm_files(\n",
    "        merged, \n",
    "        restart, \n",
    "        chunk_size=10  # Process 10 frames at a time\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datDir = '/Data1/zane/Models/mincell/Mar10/'\n",
    "dateDir = 'Mar10_'\n",
    "\n",
    "# Replicate number and restart times\n",
    "Mar10reps = {\n",
    "    \"1\":[2943,5177,7071],\n",
    "    \"2\":[2941,5271],\n",
    "    \"3\":[2962,5257],\n",
    "    \"4\":[2952,5298],\n",
    "    \"5\":[2969,5337],\n",
    "    \"7\":[2959,5268],\n",
    "    \"8\":[2957,5270,7170],\n",
    "    \"9\":[2863,5125,7048],\n",
    "    \"10\":[2507,4900,6905]\n",
    "}\n",
    "Mar10reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for repID, restart_times in Mar10reps.items():\n",
    "    mergeReplicate(datDir, dateDir, repID, restart_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datDir = '/Data1/zane/Models/mincell/Mar21/'\n",
    "dateDir = 'Mar21_'\n",
    "\n",
    "# Replicate number and restart times\n",
    "Mar21reps = {\n",
    "    \"1\":[2955,5326],\n",
    "    \"2\":[2935,5230,7125],\n",
    "    \"3\":[2927,5186,7049],\n",
    "    \"4\":[2951,5274],\n",
    "    \"5\":[2943,5226,7141],\n",
    "    \"6\":[2939,5258,7177],\n",
    "    \"7\":[2923,5278],\n",
    "    \"8\":[2967,5314],\n",
    "    \"9\":[2947,5330],\n",
    "    \"10\":[2923,5178,7057],\n",
    "    \"11\":[2915,5214,7117]\n",
    "}\n",
    "Mar21reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for repID, restart_times in Mar21reps.items():\n",
    "    mergeReplicate(datDir, dateDir, repID, restart_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
